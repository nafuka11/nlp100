{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "input_str = \"stressed\"\n",
    "\n",
    "print(input_str[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "input_str = \"パタトクカシーー\"\n",
    "\n",
    "print(input_str[0::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "patrol_car = \"パトカー\"\n",
    "taxi = \"タクシー\"\n",
    "\n",
    "result = \"\"\n",
    "for i in range(len(taxi)):\n",
    "    result += patrol_car[i] + taxi[i]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  03. 円周率\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 6, 9, 2, 7, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Now I need a drink, alcoholic of course, \" \\\n",
    "           \"after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "pi = [len(word) for word in sentence.rstrip(\",.\").split()]\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C', 7: 'N', 8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mi', 13: 'Al', 14: 'Si', 15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'K', 20: 'Ca'}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. \" \\\n",
    "           \"New Nations Might Also Sign Peace Security Clause. \" \\\n",
    "           \"Arthur King Can.\"\n",
    "indexes = (1, 5, 6, 7, 8, 9, 15, 16, 19)\n",
    "\n",
    "element_symbols = {}\n",
    "for i, word in enumerate(sentence.rstrip(\",.\").split()):\n",
    "    if i + 1 in indexes:\n",
    "        element_symbols[i + 1] = word[:1]\n",
    "    else:\n",
    "        element_symbols[i + 1] = word[:2]\n",
    "\n",
    "print(element_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi-gram: [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "文字bi-gram: ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I am an NLPer\"\n",
    "\n",
    "\n",
    "def word_ngram(words, n):\n",
    "    \"\"\"単語n-gramを作成する\n",
    "\n",
    "    Args:\n",
    "        words (str): 空白区切りの文章\n",
    "        n (int): 分割する単語数\n",
    "\n",
    "    Returns:\n",
    "        単語n-gram (list)\n",
    "\n",
    "    \"\"\"\n",
    "    word_list = words.split()\n",
    "    return [word_list[i:i+n] for i in range(len(word_list) - (n - 1))]\n",
    "\n",
    "\n",
    "def character_ngram(chars, n):\n",
    "    \"\"\"文字n-gramを作成する\n",
    "\n",
    "    Args:\n",
    "        chars (str): 文字列\n",
    "        n (int): 分割する文字数\n",
    "\n",
    "    Returns:\n",
    "        文字n-gram (list)\n",
    "\n",
    "    \"\"\"\n",
    "    return [chars[i:i+n] for i in range(len(chars) - (n - 1))]\n",
    "\n",
    "\n",
    "print(f\"単語bi-gram: {word_ngram(sentence, 2)}\")\n",
    "print(f\"文字bi-gram: {character_ngram(sentence, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: {'is', 'di', 'se', 'ap', 'pa', 'ra', 'ad', 'ar'}\n",
      "Y: {'gr', 'ag', 'ph', 'ap', 'pa', 'ra', 'ar'}\n",
      "\n",
      "XとYとの和集合: {'gr', 'is', 'di', 'ag', 'ph', 'se', 'ap', 'pa', 'ra', 'ad', 'ar'}\n",
      "XとYとの積集合: {'ra', 'ar', 'ap', 'pa'}\n",
      "XとYとの差集合: {'ad', 'di', 'is', 'se'}\n",
      "\n",
      "X内に'se'を含む: True\n",
      "Y内に'se'を含む: False\n"
     ]
    }
   ],
   "source": [
    "se = \"se\"\n",
    "\n",
    "x = set(character_ngram(\"paraparaparadise\", 2))\n",
    "y = set(character_ngram(\"paragraph\", 2))\n",
    "\n",
    "print(f\"X: {x}\")\n",
    "print(f\"Y: {y}\")\n",
    "print()\n",
    "print(f\"XとYとの和集合: {x | y}\")\n",
    "print(f\"XとYとの積集合: {x & y}\")\n",
    "print(f\"XとYとの差集合: {x - y}\")\n",
    "print()\n",
    "print(f\"X内に'{se}'を含む: {se in x}\")\n",
    "print(f\"Y内に'{se}'を含む: {se in y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def make_template(x, y, z):\n",
    "    \"\"\"引数からテンプレート文字列を返す\"\"\"\n",
    "    return f\"{x}時の{y}は{z}\"\n",
    "\n",
    "print(make_template(12, \"気温\", 22.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "- 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "- その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Cibkgltizn\n"
     ]
    }
   ],
   "source": [
    "def cipher(chars):\n",
    "    \"\"\"英小文字を置換(z -> a, y -> b)した文字列を返す\n",
    "\n",
    "    Args:\n",
    "        chars (str): 置換対象文字列\n",
    "\n",
    "    Returns:\n",
    "        置換後文字列 (str)\n",
    "\n",
    "    \"\"\"\n",
    "    return \"\".join([char if not char.islower() else\n",
    "                    chr(219 - ord(char)) for char in chars])\n",
    "\n",
    "\n",
    "message = \"A Cryptogram\"\n",
    "print(cipher(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I c'unldot beeilve that I culod aulcltay uednrstnad what I was rdianeg : the paheonenml pewor of the hmaun mind .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def typoglycemia(sentence):\n",
    "    \"\"\"各単語の先頭/末尾以外の文字をランダムに入れ替えた単語列を返す\n",
    "\n",
    "    Args:\n",
    "        sentence (str): スペースで区切られた単語列\n",
    "\n",
    "    Returns:\n",
    "        各単語の先頭/末尾以外の文字をランダムに入れ替えた単語列 (str)\n",
    "\n",
    "    \"\"\"\n",
    "    return \" \".join([word if len(word) <= 4 else\n",
    "                     word[0] + \"\".join(\n",
    "                         random.sample(word[1:-1], len(word) - 2)) + word[-1]\n",
    "                     for word in sentence.split()])\n",
    "\n",
    "\n",
    "sentence = \"I couldn't believe that I could actually understand \" \\\n",
    "           \"what I was reading : the phenomenal power of the human mind .\"\n",
    "print(typoglycemia(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
